<!DOCTYPE html> <!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]--> <!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8"><![endif]--> <!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9"><![endif]--> <!--[if gt IE 8]><!--> <html class="no-js"><!--<![endif]--> <head> <meta charset="UTF-8"> <meta content="text/html; charset=UTF-8" http-equiv="Content-Type"> <meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"> <title>High Performance Computing Notes &#8211; Muyang Guo</title> <meta name="description" content="Muyang acquired B.S and M.S degree in Mechanical Engineering from Georgia Tech and is currently pusuring another M.S degree in Computational Science & Engineering"> <meta name="keywords" content="C, HPC, MPI"> <!-- Twitter Cards --> <meta name="twitter:card" content="summary"> <meta name="twitter:image" content="http://localhost:4000/assets/img/avatar.png"> <meta name="twitter:title" content="High Performance Computing Notes"> <meta name="twitter:description" content="HPC learning notes, MPI etc. etc. updating"> <!-- Open Graph --> <meta property="og:locale" content="en_US"> <meta property="og:type" content="article"> <meta property="og:title" content="High Performance Computing Notes"> <meta property="og:description" content="HPC learning notes, MPI etc. etc. updating"> <meta property="og:url" content="http://localhost:4000/MPI-Study/"> <meta property="og:site_name" content="Muyang Guo"> <meta property="og:image" content="http://localhost:4000/assets/img/avatar.png"> <link rel="canonical" href="http://localhost:4000/MPI-Study/"> <link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Muyang Guo Feed"> <!-- Handheld --> <meta name="HandheldFriendly" content="True"> <meta name="MobileOptimized" content="320"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <!-- CSS --> <link rel="stylesheet" href="http://localhost:4000/assets/css/main.css"> <!-- JS --> <script src="http://localhost:4000/assets/js/modernizr-3.3.1.custom.min.js"></script> <!-- Favicons --> <link rel="apple-touch-icon" href="http://localhost:4000/assets/img/favicons/apple-icon-precomposed.png"> <link rel="apple-touch-icon" sizes="72x72" href="http://localhost:4000/assets/img/favicons/apple-icon-72x72.png"> <link rel="apple-touch-icon" sizes="114x114" href="http://localhost:4000/assets/img/favicons/apple-icon-114x114.png"> <link rel="apple-touch-icon" sizes="144x144" href="http://localhost:4000/assets/img/favicons/apple-icon-144x144.png"> <link rel="shortcut icon" type="image/png" href="http://localhost:4000/favicon.png" /> <link rel="shortcut icon" href="http://localhost:4000/favicon.ico" /> <!-- Background Image --> <style type="text/css">body {background-image:url(http://localhost:4000/assets/img/background.jpeg); background-repeat: no-repeat; background-size: cover; }</style> <!-- Post Feature Image --> <!-- Global site tag (gtag.js) - Google Analytics --> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-157817052-1"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-157817052-1'); </script> <!-- google global ads --> <script data-ad-client="ca-pub-1032547897605308" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script> </head> <body> <nav id="dl-menu" class="dl-menuwrapper" role="navigation"> <button class="dl-trigger">Open Menu</button> <ul class="dl-menu"> <li><a href="http://localhost:4000/">Home</a></li> <li> <a href="#">About</a> <ul class="dl-submenu"> <li> <img src="http://localhost:4000/assets/img/avatar.png" alt="Muyang Guo photo" class="author-photo"> <h4>Muyang Guo</h4> <p>Muyang acquired B.S and M.S degree in Mechanical Engineering from Georgia Tech and is currently pusuring another M.S degree in Computational Science & Engineering</p> </li> <li><a href="http://localhost:4000/about/"><span class="btn btn-inverse">Learn More</span></a></li> <li> <a href="mailto:muyangguo@gmail.com" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-envelope-square"></i> Email</a> </li> <li> <a href="https://linkedin.com/in/muyang-guo-445a3465" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-linkedin-square"></i> LinkedIn</a> </li> <li> <a href="https://github.com/MUYANGGUO" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-github"></i> Github</a> </li> </ul><!-- /.dl-submenu --> </li> <li> <a href="#">Tech Blogs</a> <ul class="dl-submenu"> <li><a href="http://localhost:4000/posts/">All Tech Blogs</a></li> <li><a href="http://localhost:4000/tags/">All Tags</a></li> </ul> </li> <li><a href="http://localhost:4000/projects/" >Projects</a></li> </ul><!-- /.dl-menu --> </nav><!-- /.dl-menuwrapper --> <div class="sidenav"> <h1 >Search</h1> <h1 > <script async src="https://cse.google.com/cse.js?cx=000703603923980589510:t0yhdcd_f-u"></script> <div class="gcse-search"></div> </h1> <hr class="hr-line"> <h1 >Website Live Stats</h1> <!-- statistics --> <h1 > <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5i5a5rwv7vf&amp;m=0c&amp;c=ff007e&amp;cr1=fff600&amp;f=times_new_roman&amp;l=49&amp;bv=85&amp;cw=ffffff&amp;cb=000000" async="async"></script> </h1> <hr class="hr-line"> </div> <!-- Header --> <header class="header" role="banner"> <div class="wrapper animated fadeIn"> <div class="content"> <div class="post-title "> <h1>High Performance Computing Notes</h1> <h4>01 Feb 2020</h4> <p class="reading-time"> <i class="fa fa-clock-o"></i> Reading time ~14 minutes </p><!-- /.entry-reading-time --> <a class="btn zoombtn" href="http://localhost:4000/posts/"> <i class="fa fa-chevron-left"></i> </a> </div> <blockquote> <p>This notes and learnings are collected during Georgia Tech’s CSE6220 HPC Class (Professor Umit Catalyurek). The documented masterial below is my notes taken during the class, in combination with my class projects notes. The collection is for my self learning documentation purpose only.</p> </blockquote> <h2 id="table-of-contents-">Table of Contents <a name="index"></a></h2> <ul> <li><a href="#intro">Intro- Installation</a></li> <li><a href="#01">Chapter 01 Sum</a></li> <li><a href="#02">Chapter 02 Prefix Sum</a></li> <li><a href="#03">Chapter 03 MPI Collective</a></li> <li><a href="#04">Chapter 04 MPI Reduction </a></li> <li><a href="#05">Chapter 05 MPI Datatype</a></li> <li><a href="#06">Chapter 06 Communication Primitives</a></li> <li><a href="#07">Chapter 07 Bitonic Sort</a></li> <li><a href="#08">Chapter 08 Sample Sort</a></li> <li><a href="#09">Chapter 09 Embeddings</a></li> <li><a href="#add">Additional Resources</a></li> </ul> <h2 id="install-mpich-on-local-machines-">Install MPICH on local machines: <a name="intro"></a></h2> <p>For my ubuntu and mac:<br /></p> <ol> <li>Install MPICH from the tar ball: <a href="https://www.mpich.org/downloads/">mpich-3.3.2</a> <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ wget http://www.mpich.org/static/downloads/3.3.2/mpich-3.3.2.tar.gz
$ tar -xzf mpich-3.3.2.tar.gz
$ cd mpich-3.3.2
</code></pre></div> </div> </li> <li>Configure, avoid building fortran library as not needed: <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ./configure --disable-fortran
</code></pre></div> </div> <p>… Wait until the command logs showing Configuration completed.</p> </li> <li>Make and install: <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ make; sudo make install
</code></pre></div> </div> </li> <li>test with <code class="highlighter-rouge">$ mpiexec --version</code>, if make is successful, call this command, will have the following: <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>HYDRA build details:
 Version:                                 3.3.2
 Release Date:                            Tue Nov 12 21:23:16 CST 2019
 CC:                              gcc    
 CXX:                             g++    
 F77:                             
 F90:                             
 Configure options:                       '--disable-option-checking' '--prefix=NONE' '--disable-fortran' '--cache-file=/dev/null' '--srcdir=.' 'CC=gcc' 'CFLAGS= -O2' 'LDFLAGS=' 'LIBS=' 'CPPFLAGS= -I/home/muyangguo/mpich-3.3.2/src/mpl/include -I/home/muyangguo/mpich-3.3.2/src/mpl/include -I/home/muyangguo/mpich-3.3.2/src/openpa/src -I/home/muyangguo/mpich-3.3.2/src/openpa/src -D_REENTRANT -I/home/muyangguo/mpich-3.3.2/src/mpi/romio/include' 'MPLLIBNAME=mpl'
 Process Manager:                         pmi
 Launchers available:                     ssh rsh fork slurm ll lsf sge manual persist
 Topology libraries available:            hwloc
 Resource management kernels available:   user slurm ll lsf sge pbs cobalt
 Checkpointing libraries available:       
 Demux engines available:                 poll select
</code></pre></div> </div> </li> </ol> <p>The cluster used MPI lib is mvapich2, I chose to use MPICH on my local machine, as many features for clusters and networks are not needed. Alternatively, another open source distribution is OpenMPI. I just go with MPICH, either one should work.</p> <p><a href="#index">Back to Table of Content</a></p> <hr /> <h2 id="01-a-sum-algorithm-to-start-">01. A Sum algorithm to start: <a name="01"></a></h2> <p>This is a programming assignment from my 6220 class, to perform a sum with MPI.</p> <p>The code is archived <a href="https://github.com/MUYANGGUO/CSE6220-HPC/blob/master/projects/project-1/prog1.cpp">here</a></p> <div style="overflow:scroll; height: 500px;"> <figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="cp">#include &lt;mpi.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;math.h&gt;
</span>
<span class="cp">#define MPI_CHK(err) if (err != MPI_SUCCESS) return err
</span>
<span class="kt">double</span> <span class="nf">local_sum</span><span class="p">(</span><span class="kt">long</span> <span class="kt">int</span> <span class="n">local_n</span><span class="p">,</span><span class="kt">long</span> <span class="kt">int</span> <span class="n">local_c</span><span class="p">,</span><span class="kt">double</span> <span class="n">local_nums</span><span class="p">[],</span><span class="kt">double</span><span class="o">*</span> <span class="n">p</span><span class="p">);</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span> <span class="p">{</span>
    <span class="k">if</span><span class="p">(</span><span class="n">argc</span><span class="o">!=</span><span class="mi">3</span><span class="p">){</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span><span class="s">"argc invalid, must have N, C specified. aborting the program ... </span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
        <span class="n">exit</span><span class="p">(</span><span class="n">EXIT_FAILURE</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="kt">int</span> <span class="n">rank</span><span class="p">,</span><span class="n">size</span><span class="p">;</span>
    <span class="c1">// Initialize the MPI environment</span>
    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">rank</span><span class="p">);</span>
    <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">size</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">p</span> <span class="o">=</span> <span class="n">size</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">err</span><span class="p">;</span>
    <span class="k">const</span> <span class="kt">int</span> <span class="n">root</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="kt">long</span> <span class="kt">int</span> <span class="n">arg_buff</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">rank</span> <span class="o">==</span> <span class="n">root</span><span class="p">){</span>
        <span class="n">arg_buff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">=</span> <span class="n">atoi</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
        <span class="n">arg_buff</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">atoi</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">]);</span>
    <span class="p">}</span>
    <span class="c1">// all ranks start calling MPI_Bcast, root to all other ranks, assign a buff to send the argv, buff = [n,c], already converted to int type</span>
    <span class="n">MPI_Bcast</span><span class="p">(</span><span class="o">&amp;</span><span class="n">arg_buff</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">MPI_DOUBLE</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
    <span class="c1">//start the timer</span>
    <span class="kt">double</span> <span class="n">t_start</span> <span class="o">=</span> <span class="n">MPI_Wtime</span><span class="p">();</span>
    <span class="c1">//after Bcast, cast values to variable n, c , and calculate each rank's new seed number </span>
    <span class="kt">long</span> <span class="kt">int</span> <span class="n">n</span><span class="p">;</span>
    <span class="kt">long</span> <span class="kt">int</span> <span class="n">c</span><span class="p">;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">arg_buff</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">arg_buff</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
    <span class="kt">long</span> <span class="kt">int</span> <span class="n">local_c</span><span class="p">;</span>
    <span class="n">local_c</span> <span class="o">=</span> <span class="n">c</span><span class="o">+</span><span class="n">rank</span><span class="p">;</span>
    <span class="c1">// printf("[%d]: After Bcast, number size is %li, new seed number is %li\n",rank, n, local_c);</span>
    <span class="kt">int</span> <span class="n">d</span> <span class="o">=</span> <span class="n">log2</span><span class="p">(</span><span class="n">p</span><span class="p">);</span>
    <span class="c1">//printf("[%d]: is having %d dimensions \n",rank,d);</span>
    <span class="c1">// consider the N/P, N is not divisible by P cases, we need to assign the maximum numbers for a rank, so some may have one more number than the other.</span>
    <span class="kt">int</span> <span class="n">local_n</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">remainder</span> <span class="o">=</span> <span class="n">n</span><span class="o">%</span><span class="n">size</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">remainder</span> <span class="o">!=</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">remainder</span> <span class="o">&gt;=</span> <span class="n">rank</span><span class="o">+</span><span class="mi">1</span><span class="p">){</span>
        <span class="n">local_n</span> <span class="o">=</span> <span class="n">n</span><span class="o">/</span><span class="n">size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
        <span class="c1">//printf("[%d]: assigned %d size numbers to this processor\n",rank, local_n);</span>
    <span class="p">}</span>
    <span class="k">else</span><span class="p">{</span>
        <span class="n">local_n</span> <span class="o">=</span> <span class="n">n</span><span class="o">/</span><span class="n">size</span><span class="p">;</span>
        <span class="c1">//printf("[%d]: assigned %d size numbers to this processor\n",rank, local_n);</span>
    <span class="p">}</span>
    <span class="c1">// after calculated the local_c, the seed for each processor, and the local_n, the number size     //assigned to each processor. </span>
    <span class="c1">// we need to generate the random numbers based on the local_c, local_n;</span>
    <span class="c1">//specify the request array size, based on local_n assigned to each processor</span>
    <span class="kt">double</span> <span class="n">local_nums</span><span class="p">[</span><span class="n">local_n</span><span class="o">+</span><span class="mi">1</span><span class="p">];</span>
    <span class="c1">//malloc the memory needed</span>
    <span class="kt">double</span><span class="o">*</span> <span class="n">ptr</span> <span class="o">=</span> <span class="p">(</span><span class="kt">double</span> <span class="o">*</span><span class="p">)</span> <span class="n">malloc</span> <span class="p">(</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">)</span> <span class="o">*</span> <span class="n">local_n</span> <span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">ptr</span> <span class="o">==</span> <span class="nb">NULL</span><span class="p">){</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"[%d]: Error! memory not allocated.</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">rank</span><span class="p">);</span>
        <span class="n">exit</span><span class="p">(</span><span class="n">EXIT_FAILURE</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="kt">double</span> <span class="n">local_s</span> <span class="o">=</span> <span class="n">local_sum</span><span class="p">(</span><span class="n">local_n</span><span class="p">,</span><span class="n">local_c</span><span class="p">,</span><span class="n">local_nums</span><span class="p">,</span><span class="n">ptr</span><span class="p">);</span>
    <span class="n">free</span><span class="p">(</span><span class="n">ptr</span><span class="p">);</span>
    <span class="n">ptr</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
    <span class="c1">//start send local sum in pairs </span>
    <span class="k">for</span><span class="p">(</span> <span class="kt">int</span> <span class="n">j</span><span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">d</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span> <span class="p">){</span>
        <span class="kt">int</span> <span class="n">bit</span> <span class="o">=</span> <span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">j</span><span class="p">);</span>
        <span class="k">if</span> <span class="p">((</span><span class="n">rank</span> <span class="o">&amp;</span> <span class="n">bit</span><span class="p">)</span> <span class="o">!=</span><span class="mi">0</span><span class="p">){</span>
            <span class="c1">// printf("j = %d with rank %d, send to %d\n",j,rank,(rank ^ bit));</span>
            <span class="n">MPI_Send</span><span class="p">(</span><span class="o">&amp;</span><span class="n">local_s</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_DOUBLE</span><span class="p">,(</span><span class="n">rank</span> <span class="o">^</span> <span class="n">bit</span><span class="p">),</span> <span class="mi">111</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
            <span class="n">MPI_Finalize</span><span class="p">();</span>
            <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="k">else</span><span class="p">{</span>
            <span class="n">MPI_Status</span> <span class="n">stat</span><span class="p">;</span>
            <span class="kt">double</span> <span class="n">local_s_received</span><span class="p">;</span>
            <span class="n">MPI_Recv</span> <span class="p">(</span><span class="o">&amp;</span><span class="n">local_s_received</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_DOUBLE</span><span class="p">,</span> <span class="p">(</span><span class="n">rank</span> <span class="o">^</span> <span class="n">bit</span><span class="p">),</span> <span class="mi">111</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">stat</span><span class="p">);</span>
            <span class="n">local_s</span> <span class="o">=</span> <span class="n">local_s</span><span class="o">+</span><span class="n">local_s_received</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span> 
    <span class="k">if</span> <span class="p">(</span><span class="n">rank</span><span class="o">==</span><span class="mi">0</span><span class="p">){</span>
    <span class="kt">double</span> <span class="n">sum</span> <span class="o">=</span> <span class="n">local_s</span><span class="p">;</span>
    <span class="kt">double</span> <span class="n">t_end</span> <span class="o">=</span> <span class="n">MPI_Wtime</span><span class="p">();</span>
    <span class="kt">double</span> <span class="n">t_running</span> <span class="o">=</span> <span class="n">t_end</span> <span class="o">-</span> <span class="n">t_start</span><span class="p">;</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"sum is: %f"</span><span class="p">,</span><span class="n">sum</span><span class="p">);</span>
    <span class="kt">FILE</span> <span class="o">*</span><span class="n">f</span> <span class="o">=</span> <span class="n">fopen</span><span class="p">(</span><span class="s">"output.txt"</span><span class="p">,</span> <span class="s">"a+"</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">f</span> <span class="o">==</span> <span class="nb">NULL</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"Error opening file!</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
        <span class="n">exit</span><span class="p">(</span><span class="n">EXIT_FAILURE</span><span class="p">);</span>
    <span class="p">}</span>  
    <span class="n">fprintf</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="s">"N= %ld, P = %d, C= %ld, S= %f</span><span class="se">\n</span><span class="s">Time= %f</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span><span class="n">p</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">sum</span><span class="p">,</span><span class="n">t_running</span><span class="p">);</span>
    <span class="n">fclose</span><span class="p">(</span><span class="n">f</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="c1">// Finalize the MPI environment.</span>
    <span class="n">MPI_Finalize</span><span class="p">();</span>
<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
<span class="kt">double</span> <span class="nf">local_sum</span><span class="p">(</span><span class="kt">long</span> <span class="kt">int</span> <span class="n">local_n</span><span class="p">,</span><span class="kt">long</span> <span class="kt">int</span> <span class="n">local_c</span><span class="p">,</span> <span class="kt">double</span> <span class="n">local_nums</span><span class="p">[],</span><span class="kt">double</span><span class="o">*</span> <span class="n">p</span><span class="p">){</span>
    <span class="kt">double</span> <span class="n">local_s</span><span class="p">;</span>
    <span class="n">srand48</span><span class="p">(</span><span class="n">local_c</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">i</span><span class="p">;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">local_nums</span><span class="p">;</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">local_n</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">){</span>
        <span class="n">local_nums</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">drand48</span><span class="p">();</span>
        <span class="c1">// printf(" generating:%f \n",local_nums[i]);</span>
        <span class="n">local_s</span> <span class="o">=</span> <span class="n">local_s</span> <span class="o">+</span> <span class="n">local_nums</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">local_s</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure> </div> <hr /> <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mpicxx ./prog1.cpp -o prog1
mpirun -np 8 ./prog1 500 1
</code></pre></div></div> <p>The algorithm is simple but very informative:</p> <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Algorithm (for P_i)
sum = add local N / P numbers
for j = 0 to d-1 {
if ((rank AND 2^j)!= 0) {
send sum to (rank XOR 2^j);
exit;
}
else {
receive sum' from (rank XOR 2^j);
sum = sum + sum';
}
}
if (rank == 0)
</code></pre></div></div> <p>And here we use dimension d to determine which pairs of processors communicate with each other. And we use bitwise operator to XOR and AND to find the pairs for iterations. We could do that because the the sum should have log(P) iterations and we considered p is a power of 2.</p> <h3 id="some-learning-notes-to-pay-attention-for-this-example">some learning notes to pay attention for this example</h3> <ol> <li>MPI_Bcast is a MPI step all processors need to perform.</li> <li>For long int, we should use MPI_DOUBLE</li> <li>Since it is log(P) iterations and sum goes to one last processor(root), we should exit the MPI for processors done their jobs during the iterations and won’t need to communicate with others , by using MPI_Finalize() and return to exit the process.</li> <li>for N sizes not dividable for P, we could allocate n and n+1 sizes by calculating the mod and compare to the rank nums.</li> </ol> <p><a href="#index">Back to Table of Content</a></p> <hr /> <h2 id="02-parallel-prefix-sum-">02. Parallel Prefix Sum: <a name="02"></a></h2> <p>Input: n numbers: \(x_0, x_1,...,x_n\) <br /> Output: \(S_0, S_1, ... , S_n\)<br /> Math: \(S_i = \sum_{j=0}^{i}x_j\)<br /></p> <h4 id="parallel-prefix-sum-alg-1">Parallel Prefix Sum Alg-1</h4> <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Algorithm-1 (for Pi)， suppose for n number, we have p=n processors

total_sum←prefix_sum←local_number
for j=0 to d-1 do 
	rank’ ←rank XOR 2^j
	send total_sum to rank’
	receive received_sum from rank’ 
	total_sum←total_sum+ received_sum
	if (rank &gt; rank’)
		prefix_sum←prefix_sum+ received_sum
endfor
</code></pre></div></div> <p><img src="https://drive.google.com/uc?id=1CSurQ5WZjTEwmn7RJsNLDWut64s3ZUJu" alt="Alg01" /> <strong><em>here black color denote prefix sum, read denote total sum</em></strong><br /> However, if n&gt;p_new, we have to use Brent’s Lemma, to let each p_new_i simulate p/p_new_i’s processors. <br /> So each p_new_i will have to assign a chunk of n numbers locally and perform the Alg-1.<br /></p> <figure> <img src="https://drive.google.com/uc?id=1TpoqaOvbKtq3hB6OVaz976oMPf2a9SxY" style="width:400px;height:300px;" /> </figure> <h4 id="parallel-prefix-sum-alg-2">Parallel Prefix Sum Alg-2</h4> <p>1.Compute prefix sum locally on each processor 2.Perform parallel prefix sum (Alg-1)<em>[1] using the last local prefix sum on each processor 3.Add the result of parallel prefix sum on a processor to each of its local prefix sum <img src="https://drive.google.com/uc?id=1TeHDcuiIXvH_n407YZ7srMCXG7qJ-T7-" alt="Alg02" /> <strong>*here black color denote prefix sum, read denote total sum</strong></em> <br /> *[1] We need to <strong>Modify Alg-2 to start with prefix_sum←0</strong> <br /> <img src="https://drive.google.com/uc?id=1w-pjFWgIwWjgyrCNBJlQ7uKiV4q7QA4A" alt="Alg02-1" /></p> <p>Note: <br /></p> <ul> <li>What if n is not divisible by p? <br /> Assign max \(\frac{n}{p}\) to each processor: some processors will have 1 more element than the others.<br /></li> <li>What if p is not a power of 2?<br /> Find p’= a power of 2 such that p’/2 &lt; p &lt; p’. Run the code like you have p’ processors.Ignore communications to/from non-existing processors, i.e., rank &gt;= p.</li> </ul> <p><a href="#index">Back to Table of Content</a></p> <hr /> <h2 id="03-mpi-study---collective-primitives-">03 MPI Study - Collective Primitives <a name="03"></a></h2> <h3 id="collective-communication">Collective Communication:</h3> <ul> <li>All processes within a comminicator must participate</li> <li>All collective operations are <strong>blocking</strong></li> <li>Except for MPI_Barrier, No synchronization can be assumed.</li> <li>All collective opertations are guaranteed to not interfere with point-to-point message.</li> <li>Collective operations can be impletemented using only point-to-point calss.</li> <li>In practice, they are optimized to use various hardware (interconnected) properties.</li> </ul> <h3 id="barrier">Barrier:</h3> <ul> <li>Block until all processes called the barrier: <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">MPI_Barrier</span><span class="p">(</span><span class="n">MPI_Commcomm</span><span class="p">);</span>
</code></pre></div> </div> </li> <li>Establish full synchronization</li> </ul> <h3 id="measuring-time">Measuring time:</h3> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include &lt;mpi.h&gt;
#include &lt;iostream&gt;
</span><span class="n">intmain</span><span class="p">(</span><span class="n">intargc</span><span class="p">,</span> <span class="kt">char</span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span> <span class="p">{</span>
    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
    <span class="n">doublet0</span> <span class="o">=</span><span class="n">MPI_Wtime</span><span class="p">();</span><span class="c1">// ...</span>
    <span class="n">MPI_Barrier</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
    <span class="n">doublet1</span> <span class="o">=</span><span class="n">MPI_Wtime</span><span class="p">();</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="o">&lt;&lt;</span><span class="p">(</span><span class="n">t1</span> <span class="o">-</span><span class="n">t0</span><span class="p">)</span> <span class="o">&lt;&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span><span class="n">returnMPI_Finalize</span><span class="p">();</span>
    <span class="p">}</span>
</code></pre></div></div> <p>MPI provides a function to check execution time:<br /></p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">double</span> <span class="nf">MPI_Wtime</span><span class="p">();</span>
</code></pre></div></div> <h3 id="broadcast">Broadcast:</h3> <p>Broadcast a message from one process (root) to all other processes:</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">MPI_Bcast</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">buf</span><span class="p">,</span> <span class="kt">int</span> <span class="n">count</span><span class="p">,</span> <span class="n">MPI_Datatype</span> <span class="n">type</span><span class="p">,</span><span class="kt">int</span> <span class="n">root</span><span class="p">,</span> <span class="n">MPI_Comm</span> <span class="n">comm</span><span class="p">);</span>
</code></pre></div></div> <p>Example:</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include &lt;mpi.h&gt;
#include &lt;iostream&gt;
</span><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="n">intargc</span><span class="p">,</span><span class="kt">char</span><span class="o">*</span><span class="n">argv</span><span class="p">[]){</span>
    <span class="kt">int</span> <span class="n">rank</span><span class="p">;</span>
    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span><span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="o">&amp;</span><span class="n">rank</span><span class="p">);</span>
    <span class="kt">double</span> <span class="n">x</span> <span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="n">rank</span> <span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="n">x</span> <span class="o">=-</span><span class="mf">13.13</span><span class="p">;</span>
    <span class="n">MPI_Bcast</span><span class="p">(</span><span class="o">&amp;</span><span class="n">x</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="o">&lt;&lt;</span><span class="n">x</span> <span class="o">&lt;&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="n">returnMPI_Finalize</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div></div> <h3 id="gather">Gather:</h3> <p>Gather data from all processes to one process(root). Like each friend bring a dish to the host’s home.</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">MPI_Gather</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">sbuf</span><span class="p">,</span> <span class="kt">int</span> <span class="n">scount</span><span class="p">,</span> <span class="n">MPI_Datatype</span> <span class="n">stype</span><span class="p">,</span> <span class="kt">void</span><span class="o">*</span> <span class="n">rbuf</span><span class="p">,</span> <span class="kt">int</span> <span class="n">rcount</span><span class="p">,</span> <span class="n">MPI_Datatype</span> <span class="n">rtype</span><span class="p">,</span> <span class="kt">int</span> <span class="n">root</span><span class="p">,</span> <span class="n">MPI_Comm</span> <span class="n">comm</span><span class="p">);</span> 
</code></pre></div></div> <p>Example:</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include &lt;mpi.h&gt;
#include &lt;iostream&gt;
#include &lt;vector &gt;
</span><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="n">intargc</span><span class="p">,</span><span class="kt">char</span><span class="o">*</span><span class="n">argv</span><span class="p">[]){</span>
    <span class="kt">int</span> <span class="n">rank</span><span class="p">,</span><span class="n">size</span><span class="p">;</span>
    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span><span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="o">&amp;</span><span class="n">rank</span><span class="p">);</span>
    <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="o">&amp;</span><span class="n">size</span><span class="p">);</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="n">buf</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="n">rank</span> <span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="n">buf</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">size</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">MPI_Gather</span><span class="p">(</span><span class="o">&amp;</span><span class="n">rank</span>  <span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_INT</span><span class="p">,</span><span class="o">&amp;</span><span class="n">buf</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_INT</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
    <span class="k">if</span><span class="p">(</span><span class="n">rank</span> <span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="o">&lt;&lt;</span><span class="n">buf</span><span class="p">.</span><span class="n">back</span><span class="p">()</span><span class="o">&lt;&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="n">returnMPI_Finalize</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div></div> <h3 id="scatter">Scatter:</h3> <p>Scatter data from one process to all processes:</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">MPI_Scatter</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">sbuf</span><span class="p">,</span> <span class="kt">int</span> <span class="n">scount</span><span class="p">,</span> <span class="n">MPI_Datatype</span> <span class="n">stype</span><span class="p">,</span> <span class="kt">void</span><span class="o">*</span> <span class="n">rbuf</span><span class="p">,</span> <span class="kt">int</span> <span class="n">rcount</span><span class="p">,</span> <span class="n">MPI_Datatype</span> <span class="n">rtype</span><span class="p">,</span> <span class="kt">int</span> <span class="n">root</span><span class="p">,</span> <span class="n">MPI_Comm</span> <span class="n">comm</span><span class="p">);</span> 
</code></pre></div></div> <p>Example:</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="n">intargc</span><span class="p">,</span><span class="kt">char</span><span class="o">*</span><span class="n">argv</span><span class="p">[]){</span>
    <span class="kt">int</span> <span class="n">rank</span><span class="p">,</span><span class="n">size</span><span class="p">;</span>
    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span><span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="o">&amp;</span><span class="n">rank</span><span class="p">);</span>
    <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="o">&amp;</span><span class="n">size</span><span class="p">);</span>
    <span class="kt">float</span> <span class="n">x</span> <span class="o">=</span><span class="mi">13</span><span class="p">;</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="n">buf</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="n">rank</span> <span class="o">==</span><span class="mi">0</span><span class="p">){</span><span class="n">buf</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">size</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">);</span>
                <span class="k">for</span><span class="p">(</span><span class="n">inti</span> <span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span> <span class="o">&lt;</span><span class="n">size</span><span class="p">;</span><span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="n">buf</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">i</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">MPI_Scatter</span><span class="p">(</span><span class="o">&amp;</span><span class="n">buf</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_FLOAT</span><span class="p">,</span><span class="o">&amp;</span><span class="n">x</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_FLOAT</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="o">&lt;&lt;</span><span class="n">rank</span> <span class="o">&lt;&lt;</span><span class="s">" "</span><span class="o">&lt;&lt;</span><span class="n">x</span> <span class="o">&lt;&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="n">returnMPI_Finalize</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div></div> <h3 id="scatterv">Scatterv</h3> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">MPI_Scatterv</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">sbuf</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">scounts</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">displs</span><span class="p">,</span><span class="n">MPI_Datatype</span> <span class="n">stype</span><span class="p">,</span> <span class="kt">void</span><span class="o">*</span> <span class="n">rbuf</span><span class="p">,</span> <span class="kt">int</span> <span class="n">rcount</span><span class="p">,</span> <span class="n">MPI_Datatype</span> <span class="n">rtype</span><span class="p">,</span> <span class="kt">int</span> <span class="n">root</span><span class="p">,</span> <span class="n">MPI_Comm</span> <span class="n">comm</span><span class="p">);</span> 
</code></pre></div></div> <p>Example:</p> <div style="overflow:scroll; height: 500px;"> <figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="cp">#include &lt;mpi.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;math.h&gt;
#define N 4
</span><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="n">intargc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[]){</span>
    <span class="kt">int</span> <span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">;</span><span class="c1">// this process' rank, and the number of processes</span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">sendcounts</span><span class="p">;</span>
    <span class="c1">// number of elements to send to each process</span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">displs</span><span class="p">;</span><span class="c1">// displacements where each segment begins</span>
    <span class="kt">int</span> <span class="n">sum</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="c1">// Sum of counts. Used to calculate displacements</span>
    <span class="kt">char</span> <span class="n">rec_buf</span><span class="p">[</span><span class="mi">100</span><span class="p">];</span><span class="c1">// buffer where the received data should be stored</span>
    <span class="kt">char</span> <span class="n">data</span><span class="p">[</span><span class="n">N</span><span class="p">][</span><span class="n">N</span><span class="p">]</span><span class="o">=</span><span class="p">{</span><span class="c1">// the data to be distributed{'a','b','c','d'}, </span>
    <span class="p">{</span><span class="sc">'e'</span><span class="p">,</span><span class="sc">'f'</span><span class="p">,</span><span class="sc">'g'</span><span class="p">,</span><span class="sc">'h'</span><span class="p">},{</span><span class="sc">'i'</span><span class="p">,</span><span class="sc">'j'</span><span class="p">,</span><span class="sc">'k'</span><span class="p">,</span><span class="sc">'l'</span><span class="p">},</span> <span class="p">{</span><span class="sc">'m'</span><span class="p">,</span><span class="sc">'n'</span><span class="p">,</span><span class="sc">'o'</span><span class="p">,</span><span class="sc">'p'</span><span class="p">}</span>
    <span class="p">};</span>
    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span><span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="o">&amp;</span><span class="n">rank</span><span class="p">);</span>
    <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="o">&amp;</span><span class="n">size</span><span class="p">);</span>

    <span class="n">sendcounts</span><span class="o">=</span> <span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="p">)</span> <span class="n">malloc</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">)</span><span class="o">*</span><span class="n">size</span><span class="p">);</span>
    <span class="n">displs</span><span class="o">=</span> <span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="p">)</span> <span class="n">malloc</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">)</span><span class="o">*</span><span class="n">size</span><span class="p">);</span>
    <span class="c1">// calculate send counts and displacements</span>
    <span class="kt">int</span> <span class="n">rem</span> <span class="o">=</span> <span class="p">(</span><span class="n">N</span><span class="o">*</span><span class="n">N</span><span class="p">)</span> <span class="o">%</span> <span class="n">size</span><span class="p">;</span><span class="c1">// elements remaining after division among processes</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">inti</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">size</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">sendcounts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">N</span><span class="o">*</span><span class="n">N</span><span class="p">)</span> <span class="o">/</span> <span class="n">size</span><span class="p">;</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">rem</span><span class="o">--&gt;</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">sendcounts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">++</span><span class="p">;</span>
        <span class="n">displs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sum</span><span class="p">;</span>
        <span class="n">sum</span> <span class="o">+=</span> <span class="n">sendcounts</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="p">}</span><span class="c1">// print calculated send counts and displacements for each process</span>
    <span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">rank</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">inti</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">size</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
            <span class="n">printf</span><span class="p">(</span><span class="s">"sendcounts[%d] = %d</span><span class="se">\t</span><span class="s">displs[%d] = %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">sendcounts</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">i</span><span class="p">,</span> <span class="n">displs</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="p">}</span><span class="c1">// divide the data among processes as described by sendcounts and displs</span>
    <span class="n">MPI_Scatterv</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="p">,</span> <span class="n">sendcounts</span><span class="p">,</span> <span class="n">displs</span><span class="p">,</span> <span class="n">MPI_CHAR</span><span class="p">,</span><span class="o">&amp;</span><span class="n">rec_buf</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">MPI_CHAR</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"%d: "</span><span class="p">,</span> <span class="n">rank</span><span class="p">);</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">inti</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">I</span> <span class="o">&lt;</span> <span class="n">sendcounts</span><span class="p">[</span><span class="n">rank</span><span class="p">];</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"%c</span><span class="se">\t</span><span class="s">"</span><span class="p">,</span> <span class="n">rec_buf</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="p">}</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="n">MPI_Finalize</span><span class="p">();</span>
    <span class="n">free</span><span class="p">(</span><span class="n">sendcounts</span><span class="p">);</span>
    <span class="n">free</span><span class="p">(</span><span class="n">displs</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure> </div> <p>Run:</p> <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>% mpirun-np 3 scatterv
sendcounts[0] = 6 displs[0] = 0
sendcounts[1] = 5 displs[1] = 6
sendcounts[2] = 5 displs[2] = 11
0: a b c d e f
1: g h i j k
2: l m n o p
</code></pre></div></div> <h3 id="allgather">Allgather:</h3> <p>Allgather: Corresponds to each process broadcasting its data.</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">MPI_Allgather</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">sbuf</span><span class="p">,</span> <span class="kt">int</span> <span class="n">scount</span><span class="p">,</span> <span class="n">MPI_Datatype</span> <span class="n">stype</span><span class="p">,</span> <span class="kt">void</span><span class="o">*</span> <span class="n">rbuf</span><span class="p">,</span> <span class="kt">int</span> <span class="n">rcount</span><span class="p">,</span> <span class="n">MPI_Datatype</span> <span class="n">rtype</span><span class="p">,</span> <span class="n">MPI_Comm</span> <span class="n">comm</span><span class="p">);</span> 
</code></pre></div></div> <p>Example:</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="n">intargc</span><span class="p">,</span><span class="kt">char</span><span class="o">*</span><span class="n">argv</span><span class="p">[]){</span>
    <span class="kt">int</span> <span class="n">rank</span><span class="p">,</span><span class="n">size</span><span class="p">;</span>
    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span><span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="o">&amp;</span><span class="n">rank</span><span class="p">);</span>
    <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="o">&amp;</span><span class="n">size</span><span class="p">);</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="n">buf</span><span class="p">;</span><span class="n">buf</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">size</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">MPI_Allgather</span><span class="p">(</span><span class="o">&amp;</span><span class="n">rank</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_INT</span><span class="p">,</span><span class="o">&amp;</span><span class="n">buf</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_INT</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span><span class="n">returnMPI_Finalize</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div></div> <h3 id="alltoall">AlltoAll</h3> <p>Alltoall: every process has one message for every other process</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">MPI_Alltoall</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">sbuf</span><span class="p">,</span> <span class="kt">int</span> <span class="n">scount</span><span class="p">,</span> <span class="n">MPI_Datatype</span> <span class="n">stype</span><span class="p">,</span> <span class="kt">void</span><span class="o">*</span> <span class="n">rbuf</span><span class="p">,</span> <span class="kt">int</span> <span class="n">rcount</span><span class="p">,</span> <span class="n">MPI_Datatype</span> <span class="n">rtype</span><span class="p">,</span> <span class="n">MPI_Comm</span> <span class="n">comm</span><span class="p">);</span> 
</code></pre></div></div> <p>Example:</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="n">intargc</span><span class="p">,</span><span class="kt">char</span><span class="o">*</span><span class="n">argv</span><span class="p">[]){</span>
    <span class="kt">int</span> <span class="n">rank</span><span class="p">,</span><span class="n">size</span><span class="p">;</span>
    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span><span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="o">&amp;</span><span class="n">rank</span><span class="p">);</span>
    <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="o">&amp;</span><span class="n">size</span><span class="p">);</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="n">send</span><span class="p">(</span><span class="n">size</span><span class="p">);</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="n">recv</span><span class="p">(</span><span class="n">size</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">);</span>
    <span class="k">for</span><span class="p">(</span><span class="n">inti</span> <span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span> <span class="o">&lt;</span><span class="n">size</span><span class="p">;</span><span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="n">send</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">rank</span><span class="p">;</span>
    <span class="n">MPI_Alltoall</span><span class="p">(</span><span class="o">&amp;</span><span class="n">send</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_FLOAT</span><span class="p">,</span><span class="o">&amp;</span><span class="n">recv</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_FLOAT</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
    <span class="n">returnMPI_Finalize</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div></div> <p><a href="#index">Back to Table of Content</a></p> <hr /> <h2 id="04-mpi-study---reduction-primitives-">04 MPI Study - Reduction Primitives <a name="04"></a></h2> <h3 id="mpi-reduce">MPI Reduce</h3> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">MPI_Reduce</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">sbuf</span><span class="p">,</span> <span class="kt">void</span><span class="o">*</span> <span class="n">rbuf</span><span class="p">,</span> <span class="kt">int</span> <span class="n">count</span><span class="p">,</span> <span class="n">MPI_Datatype</span> <span class="n">type</span><span class="p">,</span>   <span class="n">MPI_Op</span> <span class="n">op</span><span class="p">,</span> <span class="kt">int</span> <span class="n">root</span><span class="p">,</span> <span class="n">MPI_Comm</span> <span class="n">comm</span><span class="p">);</span> 
</code></pre></div></div> <p>Example:</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// assume each processor has one element:</span>
<span class="kt">int</span> <span class="n">a</span> <span class="o">=</span><span class="n">A</span><span class="p">[</span><span class="n">rank</span><span class="p">];</span>
<span class="kt">int</span> <span class="n">sum</span> <span class="o">=</span><span class="mi">0</span><span class="p">;</span>
<span class="n">MPI_Reduce</span><span class="p">(</span><span class="o">&amp;</span><span class="n">a</span><span class="p">,</span><span class="o">&amp;</span><span class="n">sum</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_INT</span><span class="p">,</span><span class="n">MPI_SUM</span> <span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
<span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="o">&lt;&lt;</span><span class="n">sum</span> <span class="o">&lt;&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</code></pre></div></div> <h3 id="mpi-allreduce">MPI Allreduce:</h3> <p>MPI_Allreduce= MPI_Reduce+ MPI_Bcast</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">MPI_Allreduce</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">sendbuf</span><span class="p">,</span> <span class="kt">void</span><span class="o">*</span> <span class="n">recvbuf</span><span class="p">,</span> <span class="kt">int</span> <span class="n">count</span><span class="p">,</span><span class="n">MPI_Datatype</span> <span class="n">datatype</span><span class="p">,</span> <span class="n">MPI_Op</span> <span class="n">op</span><span class="p">,</span> <span class="n">MPI_Comm</span> <span class="n">comm</span><span class="p">)</span>
</code></pre></div></div> <p>Example:</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">while</span><span class="p">(</span><span class="nb">true</span><span class="p">){</span>
    <span class="c1">// compute ...</span>
    <span class="c1">// check termination</span>
    <span class="kt">int</span> <span class="n">terminate</span> <span class="o">=</span><span class="p">...;</span>
    <span class="kt">int</span> <span class="n">result</span><span class="p">;</span>
    <span class="n">MPI_Allreduce</span><span class="p">(</span><span class="o">&amp;</span><span class="n">terminate</span><span class="p">,</span><span class="o">&amp;</span><span class="n">result</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_INT</span><span class="p">,</span><span class="n">MPI_LAND</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
    <span class="k">if</span><span class="p">(</span><span class="n">result</span> <span class="o">==</span><span class="mi">1</span><span class="p">)</span> <span class="k">break</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p><a href="#index">Back to Table of Content</a></p> <hr /> <h2 id="05-mpi-study---mpi-datatypes-">05 MPI Study - MPI Datatypes <a name="05"></a></h2> <p>[ Updating]</p> <p><a href="#index">Back to Table of Content</a></p> <hr /> <h2 id="06-communication-primitives-important-">06 Communication Primitives (Important) <a name="06"></a></h2> <p>[ Updating ]</p> <p><a href="#index">Back to Table of Content</a></p> <hr /> <h2 id="07-bitonic-sort-">07 Bitonic Sort <a name="07"></a></h2> <p><a href="https://www.geeksforgeeks.org/bitonic-sort/">Bitonic Sort Alg</a> A sequence is called Bitonic if it is first increasing, then decreasing.</p> <ul> <li>Bitonic sort does O(n Log 2n) comparisons.</li> <li>The number of comparisons done by Bitonic sort are more than popular sorting algorithms like Merge Sort [ does O(nLogn) comparisons], but Bitonice sort is better for parallel implementation because we always compare elements in predefined sequence and the sequence of comparison doesn’t depend on data. Therefore it is suitable for implementation in hardware and parallel processor array.</li> </ul> <h3 id="bitonic-sequence-three-types">Bitonic Sequence (three types)</h3> <p>Bitonic sequence: \(x_0,x_1, ... , x_{n-1}\) is bitonic if any k such that: (one of the three following types)</p> <ol> <li>\(x_0,x_1, ... , x_{k}\) is non-decreasing and \(x_{k+1},x_{k+2}, ... , x_{n-1}\) is non-increasing</li> <li>\(x_0,x_1, ... , x_{k}\) is non-increasing, and \(x_{k+1},x_{k+2}, ... , x_{n-1}\) is non-decreasing</li> <li>There is a cyclical shift of the sequence that makes (a) or (b) true.</li> </ol> <h3 id="bitonic-split">Bitonic Split:</h3> <p>A bitsonic sequence l satsfied the above types can be decomposed into \(l_{min}\),\(l_{max}\) sub sequences. This is called the bitonic split.</p> <h3 id="bitonic-lemma">Bitonic Lemma:</h3> <p>Let \(l\) be a bitonic sequence, and \(l_{min}\) and \(l_{max}\) result from its bitonic split, then the following results are met:</p> <ol> <li>\(l_{min}\) and \(l_{max}\) are also bitonic.</li> <li>And \(max(l_{min}) \leq min(l_{max})\)</li> </ol> <h4 id="sub-lemma">Sub-Lemma</h4> <p>Cyclical shift does not change the bitonicnature of the sequence nor the min (or max) element in the sequence!</p> <p>Let \(l\) be a bitonicsequence and \(l'\) be a cyclical shift.</p> <ol> <li>Bitonic split l into \(l_{min}\) and \(l_{max}\),</li> <li>Bitonic split l’ into \(l'_{min}\) and \(l'_{max}\)</li> <li>Then \(l'_{min}\) is a cyclical shift of \(l_{min}\), \(l'_{max}\) is a cyclical shift of \(l_{max}\)</li> </ol> <p><strong>Proof:</strong> <br /> Let \(l = x_0,x_1, ... , x_{n-1}\), <br /> And \(l' = x_k,x_{k+1}, ... , x_{k-1}\), <br /> \(l_{min} = min(x_0, x_{\frac{n}{2}}), min(x_1, x_{\frac{n}{2}+1}) ... min(x_{\frac{n}{2}-1}, x_{n-1})\) <br /> \(l'_{min} = min(x_k, x_{(\frac{n}{2}+k)mod n}), ...\)</p> <h3 id="bitnoic-merge">Bitnoic Merge:</h3> <p>Turning a bitonic sequence into a sorted sequence using repeated bitnoic split operations. <br /> BM(p,p) = O(log p)</p> <h3 id="bitonic-sort">Bitonic Sort:</h3> <ul> <li>BS(p,p) = BM(2,2) + BM(4,4) + … + BM(p,p)</li> <li>BS(p,p) = 1+2+3+…+ logP</li> <li>BS(p,p) = O(log^2 p)</li> </ul> <h3 id="bitonic-sort-alg">Bitonic Sort Alg:</h3> <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for i=0 to (log p)-1 do
    for j=i downto 0 do
        if (i+1)st bit is 0 then
            Compare_Exchange↑ with (Rank XOR 2j)    
        else
            CompareExchange↓ with (Rank XOR 2j)           
    endfor
endfor
</code></pre></div></div> <p><img src="https://drive.google.com/uc?id=1SsTibugE2j9fj-w0mPgAOP6PBdklI8BJ" alt="Example" /></p> <h3 id="bitonic-sort-complexity">Bitonic Sort Complexity:</h3> <ol> <li>T(p,p) = \(O(log^2 p)\)</li> <li>Computation time : \(O(log^2 p)\)</li> <li>Communication time : \(O(\tau log^{2}p + \mu log^{2}p)\)</li> </ol> <p>What if n&gt;p?</p> <ol> <li>sort n/p local elements</li> <li><strong>Run bitonic sort with CompareExchange replaced by MergeSplit</strong></li> <li>Computation time: \(O(\frac{n}{p}log\frac{n}{p}+ \frac{n}{p}log^{2}p)\)</li> <li>Communication time: \(O(\tau log^{2}p + \mu\frac{n}{p}log^{2}p)\)</li> </ol> <p><a href="#index">Back to Table of Content</a></p> <hr /> <h2 id="08-sample-sort-">08 Sample Sort <a name="08"></a></h2> <h3 id="sample-sort">Sample sort:</h3> <ol> <li>sort locally</li> <li>Find p-1 “good” splitters</li> <li>Split local sequence into p segments according to splitters</li> <li>Many-to-many communication</li> </ol> <h3 id="good-splitters">Good splitters:</h3> <ul> <li>Each processor should receive at most \(m \leq c \frac{n}{p}\) elements in 4.</li> <li>Finding splitters should not be too expensive (complexity)</li> </ul> <h3 id="finding-good-splitters-by-regular-sampling">Finding “good” Splitters by regular sampling:</h3> <ol> <li>pick p-1 equally spaced elements from the local sorted array on each processor (called local splitters from here onwards)</li> <li>Sort all p(p-1) local splitters using bitonic sort</li> <li>Pick p-1 global splitters: From the sorted local splitter array, pick last local splotter on each processor (excl. last processor)</li> <li>ALLGATHER global splitters</li> </ol> <h3 id="theorem">Theorem:</h3> <p>Each processor receives at most \(2\frac{n}{p}\) elements.</p> <h3 id="sample-sort-proof">Sample sort proof:</h3> <p><a href="#index">Back to Table of Content</a></p> <hr /> <h2 id="09-embedding-">09 Embedding: <a name="09"></a></h2> <h3 id="source--target">Source &amp; Target</h3> <ul> <li>Algorithm designed for source network.The system you have is Target network.</li> <li>Source and Target can be modeled as graphs.</li> <li>Interested in the case where Target network can support(relaxed) hypercubic permutations.</li> </ul> <h3 id="performance-metrics">Performance Metrics</h3> <p>Embedding a source graph G(V,E) into a target graph G’(V’,E’):</p> <ul> <li>Congestion : Maximum number of edges from E that are mapped onto a single edge in E’</li> <li>Dilation: Maximum number of edges in E’that any edge in Eis mapped to.</li> <li>Load: Maximum number of nodes in Vthat map to a single node in V’</li> <li>Expansion: The ratio of the number of nodes V’to that in V.</li> </ul> <p>Computation slows down by a factor of Load.<br /> Communication slows down by a factor of Congestion X Dilation.<br /> Expansion &gt; 1 indicates waste of resources.<br />Mapping: Load = Congestion = Dilation = 1</p> <h3 id="key-ideas">Key Ideas:</h3> <p>When embedding from sources to target is a mapping:</p> <ul> <li>Mapping only needs to specify node mapping. Edge mapping is implied.</li> <li>Parallel run-time on the target topology is the same as that on the source topology.</li> <li>Efficiency is preserved when execution of the algorithm is shifted from source topology to target topology!</li> <li>It is possible there can be a different parallel algorithm with better efficiency directly designed for the target topology.</li> <li>This concern is eliminated if the parallel algorithm designed for the source topology is optimally efficient.</li> </ul> <h3 id="linear-arrays">Linear Arrays</h3> <p><a href="#index">Back to Table of Content</a></p> <hr /> <h2 id="additional-resources-">Additional Resources <a name="add"></a></h2> <p><a href="#index">Back to Table of Content</a></p> <hr /> <hr /> <p>Copyright 2019 Muyang Guo, all rights reserved. Redistribution of the work must cite the original source.</p> <div class="entry-meta"> <br> <hr> <span class="entry-tags"><a href="http://localhost:4000/tags/#C" title="Pages tagged C" class="tag"><span class="term">C</span></a><a href="http://localhost:4000/tags/#HPC" title="Pages tagged HPC" class="tag"><span class="term">HPC</span></a><a href="http://localhost:4000/tags/#MPI" title="Pages tagged MPI" class="tag"><span class="term">MPI</span></a></span> <span class="social-share"> <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/MPI-Study/" title="Share on Facebook" class="tag"> <span class="term"><i class="fa fa-facebook-square"></i> Share</span> </a> <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/MPI-Study/" title="Share on Linkedin" class="tag"> <span class="term"><i class="fa fa-linkedin-square"></i> Share</span> </a> <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/MPI-Study/" title="Share on Twitter" class="tag"> <span class="term"><i class="fa fa-twitter-square"></i> Tweet</span> </a> </span> <div style="clear:both"></div> </div> </div> </div> <section id="disqus_thread" class="animated fadeInUp"></section><!-- /#disqus_thread --> </header> <!-- JS --> <script src="http://localhost:4000/assets/js/jquery-1.12.0.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.dlmenu.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.goup.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.magnific-popup.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.fitvid.min.js"></script> <script src="http://localhost:4000/assets/js/scripts.js"></script> <script type="text/javascript"> var disqus_shortname = 'muyangguo'; (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js'; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })(); (function () { var s = document.createElement('script'); s.async = true; s.type = 'text/javascript'; s.src = '//' + disqus_shortname + '.disqus.com/count.js'; (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s); }()); </script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript> <!-- MathJax --> <script async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> </body> </html>
